{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading input data\n",
    "data = np.genfromtxt('./data/tt.csv', delimiter=',')\n",
    "y = data[:,0].reshape(-1,1)\n",
    "X = data[:, 1:]\n",
    "m = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.048337698564858984\n",
      "-0.08263754254905406\n",
      "0.009939149313306292\n"
     ]
    }
   ],
   "source": [
    "# Some network architecture\n",
    "input_layer_size  = 784\n",
    "hidden_layer_size = 28\n",
    "num_labels = 26\n",
    "_lambda = 0\n",
    "theta1 = np.random.rand(hidden_layer_size,785) * 2 * 0.11 - 0.11 #dimension(hidden layer size, input layer size + 1)\n",
    "theta2 = np.random.rand(num_labels,hidden_layer_size + 1) * 2 * 0.11 - 0.11  #dimension(hiddent layer size + 1, labels)\n",
    "#theta1 shape: (28, 785)\n",
    "#theta2 shape: (26, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/kaleko/CourseraML/\n",
    "def flatten_params(thetas_list):\n",
    "    \"\"\"\n",
    "    Hand this function a list of theta matrices, and it will flatten it\n",
    "    into one long (n,1) shaped numpy array\n",
    "    \"\"\"\n",
    "    flattened_list = [ mytheta.flatten() for mytheta in thetas_list ]\n",
    "    combined = list(itertools.chain.from_iterable(flattened_list))\n",
    "    assert len(combined) == (input_layer_size+1)*hidden_layer_size + (hidden_layer_size+1)*num_labels\n",
    "    return np.array(combined).reshape((len(combined),1))\n",
    "\n",
    "def reshape_params(flattened_array):\n",
    "    theta1 = flattened_array[:(input_layer_size+1)*hidden_layer_size].reshape((hidden_layer_size,input_layer_size+1))\n",
    "    theta2 = flattened_array[(input_layer_size+1)*hidden_layer_size:].reshape((num_labels,hidden_layer_size+1))\n",
    "    return [ theta1, theta2 ]\n",
    "\n",
    "def flattenX(myX):\n",
    "    return np.array(myX.flatten()).reshape((n_training_samples*(input_layer_size+1),1))\n",
    "\n",
    "def reshapeX(flattenedX):\n",
    "    return np.array(flattenedX).reshape((n_training_samples,input_layer_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta1: (28, 785), theta2: (26, 29)\n",
      "(22734, 1)\n"
     ]
    }
   ],
   "source": [
    "# Flatten thetas\n",
    "print(f'theta1: {np.shape(theta1)}, theta2: {np.shape(theta2)}')\n",
    "nn_params = flatten_params([theta1, theta2])\n",
    "print(np.shape(nn_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return ( (1 / (1 + np.exp(-z))) )\n",
    "\n",
    "def sigmoid_gradient(z):\n",
    "    return (sigmoid(z) * (1 - sigmoid(z)))\n",
    "\n",
    "print(sigmoid(0.0)) #should return 0.5\n",
    "print(sigmoid_gradient(0.0)) # should return 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nncost_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, _lambda):\n",
    "    # Reshape nn params and some initializations\n",
    "    theta1, theta2 = reshape_params(nn_params)     \n",
    "    J = 0\n",
    "    theta1_grad = np.zeros(np.shape(theta1))  # Used for gradient \n",
    "    theta2_grad = np.zeros(np.shape(theta2))  # Used for gradient \n",
    "    \n",
    "    # feed forward propogation\n",
    "    '''\n",
    "    a1 = (m, input_layer_size + 1), a2 = (m, hidden_layer_size + 1), a3= (m, num_labels)\n",
    "    theta1 = (hidden_layer_size, input_layer_size + 1)\n",
    "    theta2 = (num_labels, hidden_layer_size)\n",
    "    '''\n",
    "    # Input layer\n",
    "    a1 = np.c_[np.ones((m,1)), X] # assigning a1 to X, and adding a bias (m, input_layer_size + 1)\n",
    "    # Hidden layer\n",
    "    z2 = a1.dot(theta1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.c_[np.ones((np.shape(a2)[0], 1)), a2] # bias for hidden layer\n",
    "    # Output layer\n",
    "    z3 = a2.dot(theta2.T)\n",
    "    a3 = sigmoid(z3) #a3 = h(x)\n",
    "    \n",
    "    # Compute cost\n",
    "    # fill array of \n",
    "    y_k = np.zeros((m,num_labels))\n",
    "    for i in range(0,m):\n",
    "        label_index = int(y[i])\n",
    "        y_k[i,label_index] = 1\n",
    "    \n",
    "    # J(theta) function: cross-entropy\n",
    "    term1 = (-y_k * np.log(a3))\n",
    "    term2 = (1 - y_k) * np.log(1 - a3)\n",
    "    cost = np.sum(term1 + term2)/m\n",
    "    # Regularization sum\n",
    "    reg_term = np.sum(theta1 ** 2) + np.sum(theta2[:,1:] ** 2)\n",
    "    reg_term = (_lambda/2/m) * reg_term\n",
    "    J = cost + reg_term\n",
    "    \n",
    "    \n",
    "    # Back propogation\n",
    "    # delta_3: (m, num_labels), theta2: (num_labels, hidden_layer_size + 1(bias)) z2: (688, hidden_layer size)\n",
    "    # delta_2: (m, hidden_layer,size) a1 = (m, input_layer_size + 1) a2 = (m, hidden_layer_size + 1)\n",
    "    \n",
    "    delta_3 = a3 - y_k #(m, num_labels), theta2=(labels, hidden_label size)\n",
    "    delta_2 = (delta_3.dot(theta2))[:,1:] * sigmoid_gradient(z2) #ignore bias\n",
    "    sum_2 = delta_3.T.dot(a2) # sum of a_i * delta_i+1\n",
    "    sum_1 = delta_2.T.dot(a1)\n",
    "    \n",
    "    print(f'sum3: {np.shape(sum_2)}')\n",
    "    \n",
    "    # putting the gradient equation together\n",
    "    # !!! try running with adding in J_0 bias term\n",
    "    theta_2_grad = (sum_2[:,1:] / m) + ((theta2[:,1:] * _lambda) / m)\n",
    "    theta_1_grad = (sum_1[:,1:] / m) + (theta1[:,1:] * _lambda / m)\n",
    "    \n",
    "    # flattening grad\n",
    "    print(theta_1_grad)\n",
    "    print(theta_2_grad)\n",
    "    gradient = [theta_1_grad, theta_2_grad]\n",
    "    return (J, gradient)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum3: (26, 29)\n",
      "[[-2.08997582e-02 -2.10276967e-02 -2.12571777e-02 ... -2.64974337e-02\n",
      "  -2.58945391e-02 -2.46006286e-02]\n",
      " [ 1.41953758e-16  1.42584004e-16  9.28141158e-17 ...  3.83106161e-16\n",
      "   3.87141558e-16  3.87141558e-16]\n",
      " [ 2.71402367e-02  2.79799326e-02  2.90215025e-02 ...  3.60595701e-02\n",
      "   3.92124338e-02  3.93086416e-02]\n",
      " ...\n",
      " [ 3.71729594e-03  3.71970211e-03  3.76895698e-03 ...  5.34877837e-03\n",
      "   4.50125028e-03  4.28913896e-03]\n",
      " [ 9.47995905e-03  9.84986848e-03  1.01913816e-02 ...  4.68137221e-03\n",
      "   4.24619317e-03  4.12875856e-03]\n",
      " [-1.48826163e-02 -1.53646558e-02 -1.56104534e-02 ... -1.71372664e-02\n",
      "  -1.65892448e-02 -1.65011573e-02]]\n",
      "[[ 4.11625761e-01  4.36123999e-01  4.30061230e-01  4.36123999e-01\n",
      "   3.59194376e-01  1.05866492e-01  8.44201155e-31  3.69877955e-01\n",
      "   4.19419654e-01  1.43633805e-01  4.36123999e-01  2.76564582e-01\n",
      "   8.84960792e-03  3.93339532e-01  3.50071894e-01  4.15284851e-01\n",
      "   4.35373251e-01  8.18108709e-35  2.90716885e-01  4.36123999e-01\n",
      "   3.89313975e-31  2.70960186e-03  3.52515867e-01  4.35386720e-01\n",
      "   1.18975633e-01  4.35506129e-01  4.32104094e-01  4.02117076e-01]\n",
      " [ 4.57357367e-01  4.81496057e-01  4.75188087e-01  4.81496057e-01\n",
      "   4.04551519e-01  1.18522290e-01  7.74575123e-31  4.13835729e-01\n",
      "   4.63289792e-01  1.58163191e-01  4.81496057e-01  2.96106830e-01\n",
      "   8.21681676e-03  4.36742069e-01  3.86489388e-01  4.58684936e-01\n",
      "   4.80717324e-01  1.01761475e-34  3.04827470e-01  4.81496057e-01\n",
      "  -3.63944617e-31  2.68401707e-03  3.72085401e-01  4.80796500e-01\n",
      "   1.26189194e-01  4.80911428e-01  4.76103116e-01  4.46898089e-01]\n",
      " [ 5.06730933e-01  5.09955755e-01  5.03069296e-01  5.09955755e-01\n",
      "   4.24864612e-01  1.13181984e-01  8.81914322e-31  4.52643708e-01\n",
      "   4.88749820e-01  1.53567797e-01  5.09955755e-01  3.04742736e-01\n",
      "   9.30576645e-03  4.62828871e-01  4.08921486e-01  4.83580064e-01\n",
      "   5.10680013e-01  1.17808009e-34  3.08640672e-01  5.09955755e-01\n",
      "   3.93379266e-31  3.31736223e-03  4.07157288e-01  5.09182799e-01\n",
      "   1.52550837e-01  5.09304871e-01  5.04537123e-01  4.84577530e-01]\n",
      " [ 4.18236306e-01  4.42214625e-01  4.36172497e-01  4.42214625e-01\n",
      "   3.64926537e-01  1.16165594e-01  7.84712311e-31  3.90246065e-01\n",
      "   4.25332052e-01  1.33764921e-01  4.42214625e-01  2.85920869e-01\n",
      "   8.69622745e-03  4.01302252e-01  3.61089704e-01  4.20753677e-01\n",
      "   4.41442988e-01  9.07744929e-35  2.92032836e-01  4.42214625e-01\n",
      "   3.94261295e-31  2.92833805e-03  3.55343307e-01  4.41443557e-01\n",
      "   1.21079901e-01  4.41667393e-01  4.41567619e-01  4.12140361e-01]\n",
      " [ 3.89881019e-01  4.12047017e-01  4.06591129e-01  4.12047017e-01\n",
      "   3.37373027e-01  1.03935780e-01  6.74546098e-31  3.67442348e-01\n",
      "   3.95366763e-01  1.15090048e-01  4.12047017e-01  2.67157881e-01\n",
      "   7.03179876e-03  3.78711871e-01  3.41466556e-01  3.89920842e-01\n",
      "   4.11336583e-01  8.52926390e-35  2.66709848e-01  4.12047017e-01\n",
      "   3.51345966e-31  2.67440884e-03  3.43863396e-01  4.11346809e-01\n",
      "   1.17300623e-01  4.11476419e-01  4.08043260e-01  3.83267828e-01]\n",
      " [ 5.36536449e-01  5.61881900e-01  5.57003231e-01  5.61881900e-01\n",
      "   4.72581121e-01  1.38691222e-01  8.65825003e-31  4.90664850e-01\n",
      "   5.40360327e-01  1.64087575e-01  5.61881900e-01  3.52687302e-01\n",
      "   1.04335194e-02  5.06130516e-01  4.69785179e-01  5.34132738e-01\n",
      "   5.61091532e-01  1.22520168e-34  3.64888782e-01  5.61881900e-01\n",
      "   4.83647537e-31  3.33222219e-03  4.46174606e-01  5.61011328e-01\n",
      "   1.52313186e-01  5.62374401e-01  5.55655715e-01  5.22799321e-01]\n",
      " [ 4.93107495e-01  5.19274677e-01  5.12058779e-01  5.19274677e-01\n",
      "   4.34388832e-01  1.10363299e-01  8.98407492e-31  4.61333134e-01\n",
      "   4.98630740e-01  1.63222938e-01  5.19274677e-01  3.38051073e-01\n",
      "   9.81216849e-03  4.66987895e-01  4.37085819e-01  4.92580881e-01\n",
      "   5.18514440e-01  1.04315521e-34  3.36638366e-01  5.19274677e-01\n",
      "   4.49907998e-31  3.28031515e-03  4.08927888e-01  5.18449263e-01\n",
      "   1.43075460e-01  5.18622137e-01  5.13482034e-01  4.80852969e-01]\n",
      " [ 6.29496796e-01  6.60374560e-01  6.52058079e-01  6.60374560e-01\n",
      "   5.56130347e-01  1.57524186e-01  1.06067695e-30  5.84729114e-01\n",
      "   6.35785297e-01  2.05254925e-01  6.60374560e-01  4.20995562e-01\n",
      "   7.01746319e-03  5.98996658e-01  5.44905378e-01  6.28988782e-01\n",
      "   6.59468447e-01  1.28960426e-34  4.22823531e-01  6.60374560e-01\n",
      "   5.33343541e-31  3.85312012e-03  5.33231285e-01  6.59421659e-01\n",
      "   1.71428091e-01  6.59525358e-01  6.53875595e-01  6.13391103e-01]\n",
      " [ 5.63904343e-01  5.95127187e-01  5.87463593e-01  5.95127187e-01\n",
      "   4.97543274e-01  1.46458346e-01  1.00918914e-30  5.16543068e-01\n",
      "   5.72466202e-01  1.82299817e-01  5.95127187e-01  3.88073140e-01\n",
      "   1.01671152e-02  5.40534901e-01  4.89359575e-01  5.67039246e-01\n",
      "   5.94176970e-01  1.15097727e-34  3.91692030e-01  5.95127187e-01\n",
      "   4.88823137e-31  3.80741373e-03  4.77219629e-01  5.94207764e-01\n",
      "   1.43619710e-01  5.94328821e-01  5.89275602e-01  5.53663218e-01]\n",
      " [ 4.26215542e-01  4.48397542e-01  4.42694185e-01  4.48397542e-01\n",
      "   3.75434083e-01  1.06286731e-01  7.26924063e-31  3.92278752e-01\n",
      "   4.31613345e-01  1.37357316e-01  4.48397542e-01  2.91300042e-01\n",
      "   7.77417046e-03  4.03580430e-01  3.70186154e-01  4.26826727e-01\n",
      "   4.47672041e-01  8.85696073e-35  2.91646601e-01  4.48397542e-01\n",
      "   4.30727083e-31  2.76668611e-03  3.54108888e-01  4.47722714e-01\n",
      "   1.23102004e-01  4.47839242e-01  4.43932342e-01  4.17151040e-01]\n",
      " [ 4.68396514e-01  4.93828801e-01  4.87394161e-01  4.93828801e-01\n",
      "   4.34896234e-01  9.70924562e-02  8.04848911e-31  4.25517995e-01\n",
      "   4.87722255e-01  1.67885096e-01  4.93828801e-01  3.24489772e-01\n",
      "   9.37875445e-03  4.53227114e-01  4.08429387e-01  4.80559776e-01\n",
      "   4.93000486e-01  1.02266468e-34  3.37727586e-01  4.93828801e-01\n",
      "   4.71544444e-31  2.86658988e-03  3.85170258e-01  4.94587217e-01\n",
      "   1.14676452e-01  4.93182815e-01  4.88621401e-01  4.61760448e-01]\n",
      " [ 4.28002151e-01  4.46005194e-01  4.39334270e-01  4.46005194e-01\n",
      "   3.75268782e-01  1.20350465e-01  8.26475182e-31  3.78390924e-01\n",
      "   4.26332761e-01  1.41215876e-01  4.46005194e-01  2.90970640e-01\n",
      "   9.44308323e-03  4.09602524e-01  3.59950735e-01  4.21977657e-01\n",
      "   4.45207558e-01  1.03227032e-34  2.77063955e-01  4.46005194e-01\n",
      "   4.46005292e-31  3.15095463e-03  3.51286880e-01  4.45228670e-01\n",
      "   1.34182979e-01  4.45409074e-01  4.40815134e-01  4.14455069e-01]\n",
      " [ 3.89341652e-01  4.09560552e-01  4.04005942e-01  4.09560552e-01\n",
      "   3.38864712e-01  9.78306098e-02  6.97240335e-31  3.54993418e-01\n",
      "   3.94174761e-01  1.27827557e-01  4.09560552e-01  2.58969350e-01\n",
      "   8.24288997e-03  3.68442039e-01  3.32924752e-01  3.89192229e-01\n",
      "   4.08957341e-01  7.62044747e-35  2.64175495e-01  4.09560552e-01\n",
      "   3.52782624e-31  2.44083220e-03  3.25403210e-01  4.08956140e-01\n",
      "   1.13887228e-01  4.09014002e-01  4.05471269e-01  3.78176123e-01]\n",
      " [ 4.38571969e-01  4.61379358e-01  4.55291137e-01  4.61379358e-01\n",
      "   3.83249667e-01  1.13535788e-01  7.91434900e-31  4.04869154e-01\n",
      "   4.42482043e-01  1.45097655e-01  4.61379358e-01  2.89222419e-01\n",
      "  -4.64145409e-04  4.17876972e-01  3.82771674e-01  4.36800192e-01\n",
      "   4.60653395e-01  1.01328409e-34  2.90266841e-01  4.61379358e-01\n",
      "   3.72063132e-31  3.14064469e-03  3.69856016e-01  4.60614527e-01\n",
      "   1.32231275e-01  4.60804770e-01  4.56459533e-01  4.29672957e-01]\n",
      " [ 4.84646455e-01  5.04264783e-01  4.97561736e-01  5.04264783e-01\n",
      "   4.15788990e-01  1.23060609e-01 -7.09610205e-31  4.47314266e-01\n",
      "   4.82867785e-01  1.46120227e-01  5.04264783e-01  3.06392896e-01\n",
      "   9.34195408e-03  4.52739898e-01  4.09710670e-01  4.77799994e-01\n",
      "   5.03516760e-01  1.18443030e-34  3.09200657e-01  5.04264783e-01\n",
      "   4.47052102e-31  1.84806609e-03  3.95733365e-01  5.03442351e-01\n",
      "   1.46455668e-01  5.03622031e-01  4.98771601e-01  4.70653966e-01]\n",
      " [ 4.06712479e-01  4.29214554e-01  4.23340966e-01  4.29214554e-01\n",
      "   3.69952455e-01  8.47513756e-02  6.76376910e-31  3.68463020e-01\n",
      "   4.14760607e-01  1.45223144e-01  4.29214554e-01  2.95992024e-01\n",
      "   8.52112718e-03  3.81538910e-01  3.56383725e-01  4.10441110e-01\n",
      "   4.28465555e-01  9.48184418e-35  2.90992309e-01  4.29214554e-01\n",
      "   3.56752056e-31  2.54284177e-03  3.39071127e-01  4.28486592e-01\n",
      "   9.04102095e-02  4.28597544e-01  4.24336523e-01  3.97957236e-01]\n",
      " [ 4.69519651e-01  4.94158719e-01  4.91316712e-01  4.94158719e-01\n",
      "   4.04598669e-01  1.15565715e-01  8.62110025e-31  4.47155500e-01\n",
      "   4.79264306e-01  1.49630480e-01  4.94158719e-01  3.20683345e-01\n",
      "   6.23260040e-03  4.44635857e-01  4.15159114e-01  4.76821615e-01\n",
      "   4.93446543e-01 -8.55637619e-35  3.12969601e-01  4.94158719e-01\n",
      "   3.98702055e-31  3.30273850e-03  4.00699633e-01  4.93329319e-01\n",
      "   1.25268776e-01  4.93552206e-01  4.91611117e-01  4.62846024e-01]\n",
      " [ 3.23393887e-01  3.40541572e-01  3.38331860e-01  3.40541572e-01\n",
      "   2.89470993e-01  8.24627714e-02  5.52782219e-31  2.93487302e-01\n",
      "   3.27773619e-01  1.19754361e-01  3.40541572e-01  2.14935812e-01\n",
      "   6.40284085e-03  3.11240279e-01  2.69291822e-01  3.26058781e-01\n",
      "   3.40024353e-01  7.91294171e-35  2.25044161e-01  3.40541572e-01\n",
      "   2.50887044e-31  2.34127496e-03  2.70428349e-01  3.39898498e-01\n",
      "   8.68351016e-02  3.40096167e-01  3.38314294e-01  3.13421911e-01]\n",
      " [ 4.00232362e-01  4.21531947e-01  4.15257602e-01  4.21531947e-01\n",
      "   3.51322849e-01  1.15842071e-01  6.96036399e-31  3.62204275e-01\n",
      "   4.02840138e-01  1.41948756e-01  4.21531947e-01  2.74204749e-01\n",
      "   7.71252655e-03  3.77504888e-01  3.43792513e-01  3.97826496e-01\n",
      "   4.20861757e-01  1.02091584e-34  2.71127661e-01  4.21531947e-01\n",
      "   3.58341970e-31  2.76467522e-03  3.39007643e-01  4.20772377e-01\n",
      "   1.15982449e-01  4.20981225e-01  4.16912038e-01  3.94733154e-01]\n",
      " [ 4.84869566e-01  5.10480926e-01  5.03277607e-01  5.10480926e-01\n",
      "   4.24025005e-01  1.28832517e-01  8.61852270e-31  4.46958547e-01\n",
      "   4.89851197e-01  1.58531831e-01  5.10480926e-01  3.28057673e-01\n",
      "   9.52154035e-03  4.54643376e-01  4.21012262e-01  4.83415037e-01\n",
      "   5.09648457e-01  1.07165506e-34  3.16780930e-01  5.10480926e-01\n",
      "   4.74163564e-31  3.26116102e-03  3.99477411e-01  5.09654832e-01\n",
      "   1.49066139e-01  5.09814411e-01  5.04954632e-01  4.68786351e-01]\n",
      " [ 4.02138125e-01  4.25269563e-01  4.20940082e-01  4.25269563e-01\n",
      "   3.59839710e-01  9.10999710e-02  7.12618599e-31  3.68126741e-01\n",
      "   4.13538161e-01  1.50278338e-01  4.25269563e-01  2.73997050e-01\n",
      "   8.03411026e-03  3.86828145e-01  3.38684922e-01  4.06009151e-01\n",
      "   4.24580407e-01  7.38261533e-35  2.84370932e-01  4.25269563e-01\n",
      "   3.31149010e-31  2.56883293e-03  3.28652629e-01  4.24663476e-01\n",
      "   1.08062520e-01  4.24655279e-01  4.21008554e-01  3.92518623e-01]\n",
      " [ 4.72258793e-01  4.97198530e-01  4.90448583e-01  4.97198530e-01\n",
      "   4.20952819e-01  1.25356640e-01  8.66210474e-31  4.33768015e-01\n",
      "   4.76996269e-01  1.64659925e-01  4.97198530e-01  3.12191724e-01\n",
      "   9.30352450e-03  4.49220953e-01  4.03418803e-01  4.73196045e-01\n",
      "   4.96469778e-01  1.08106974e-34  3.24965597e-01  4.97198530e-01\n",
      "   3.97501915e-31  3.16872791e-03  3.92809522e-01  4.96422647e-01\n",
      "   1.27841851e-01  4.96584309e-01  4.91590591e-01  4.60010823e-01]\n",
      " [ 4.79561550e-01  5.04616053e-01  4.99401172e-01  5.04616053e-01\n",
      "   4.41798569e-01  1.05257351e-01  8.66527398e-31  4.33189097e-01\n",
      "   4.90960414e-01  1.71669018e-01  5.04616053e-01  3.33440700e-01\n",
      "   9.99000666e-03  4.55756502e-01  4.05662112e-01  4.86762525e-01\n",
      "   5.03859274e-01  1.03835301e-34  3.30809521e-01  5.04616053e-01\n",
      "   4.44014952e-31  1.41740321e-04  3.94763580e-01  5.03844874e-01\n",
      "   1.26327204e-01  5.03978701e-01  4.99147262e-01  4.66053596e-01]\n",
      " [ 4.54017749e-01  4.74543428e-01  4.67934941e-01  4.74543428e-01\n",
      "   3.95536150e-01  1.04211954e-01  9.10122833e-31  4.07254093e-01\n",
      "   4.55458757e-01  1.46531565e-01  4.74543428e-01  3.12233527e-01\n",
      "   9.54924525e-03  4.30344382e-01  3.91340264e-01  4.54380238e-01\n",
      "   4.73736465e-01  1.03011348e-34  3.00600243e-01  4.74543428e-01\n",
      "   4.40258008e-31  1.80253891e-03  3.81574569e-01  4.73808046e-01\n",
      "   1.21667011e-01  4.73973894e-01  4.69177486e-01  4.42966208e-01]\n",
      " [ 5.04101492e-01  5.30427935e-01  5.23257730e-01  5.30427935e-01\n",
      "   4.51610492e-01  1.31254435e-01  8.26276447e-31  4.63356487e-01\n",
      "   5.10477751e-01  1.72533476e-01  5.30427935e-01  3.35958397e-01\n",
      "   9.26622711e-03  4.80107799e-01  4.32702033e-01  5.04684926e-01\n",
      "   5.29662771e-01  1.07949662e-34  3.55642956e-01  5.30427935e-01\n",
      "   4.20525630e-31  3.19692867e-03  4.21007105e-01  5.29618975e-01\n",
      "   1.35412279e-01  5.29734213e-01  5.24894606e-01  4.93183666e-01]\n",
      " [ 4.50899197e-01  4.73756789e-01  4.67822520e-01  4.73756789e-01\n",
      "   4.01239369e-01  1.16264157e-01  7.06364542e-31  4.13606468e-01\n",
      "   4.55723821e-01  1.53212267e-01  4.73756789e-01  3.01839863e-01\n",
      "   9.13357290e-03  4.29766901e-01  3.83687967e-01  4.50308598e-01\n",
      "   4.73051032e-01  9.67981501e-35  3.08281082e-01  4.73756789e-01\n",
      "   4.05564017e-31  2.81258309e-03  3.73195803e-01  4.73077330e-01\n",
      "   1.28761679e-01  4.73193942e-01  4.68771639e-01  4.39937015e-01]]\n"
     ]
    }
   ],
   "source": [
    "J,grad = cost_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, _lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
