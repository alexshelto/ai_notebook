{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize, special\n",
    "import itertools\n",
    "from tqdm import trange\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize weights for theta values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_initialize_weights(layer_in, layer_out):\n",
    "    # gaussian is strong\n",
    "    # uniform is stronger\n",
    "    ret = np.random.uniform(-1., 1., size=(layer_out,layer_in + 1))/np.sqrt(layer_out * layer_in)\n",
    "    return ret.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('./data/tt.csv', delimiter=',')\n",
    "y = data[:,0].reshape(-1,1)  # Shape: (688,1)\n",
    "X = data[:, 1:] / 255              # Shape: (m, input_layer_size)\n",
    "m = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: 688\n",
      "theta1 shape: (120, 785), theta2 shape: (26, 121)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd877fe1700>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "# data = np.genfromtxt('./data/sign_mnist_train.csv', delimiter=',')\n",
    "# y = data[:,0].reshape(-1,1)  # Shape: (688,1)\n",
    "# X = data[:, 1:] / 255              # Shape: (m, input_layer_size)\n",
    "# m = len(y)\n",
    "print(f'examples: {m}')\n",
    "\n",
    "input_layer_size = 784\n",
    "hidden_layer_size = 120      # hidden layer has 120 nodes excluding bias \n",
    "num_labels = 26              # 26 total output values: a=0, b=1, ... , z=25\n",
    "\n",
    "# Initialize theta values\n",
    "# theta1 size = (input_layer_size + 1, hidden_layer_size)\n",
    "# theta2 size = (hidden_layer_size + 1, num_labels)\n",
    "np.random.seed(1999)\n",
    "theta1 = rand_initialize_weights(input_layer_size, hidden_layer_size)\n",
    "theta2 = rand_initialize_weights(hidden_layer_size, num_labels)\n",
    "\n",
    "print(f'theta1 shape: {np.shape(theta1)}, theta2 shape: {np.shape(theta2)}')\n",
    "\n",
    "# supposed to be: : theta1 shape (120, 785), theta2 shape: (26, 121)\n",
    "plt.imshow(X[2].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function and derivative\n",
    "* Used for activation function in forward propogation\n",
    "* Derivative used for back propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "   # return (1 / (1 + np.exp(-z)))\n",
    "    s = expit(z)\n",
    "    return s\n",
    "\n",
    "def dx_sigmoid(z):\n",
    "    res = sigmoid(z)\n",
    "    return (res * (1 - res))\n",
    "\n",
    "print(sigmoid(0))\n",
    "print(dx_sigmoid(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_labeled(y, num_labels):\n",
    "    '''returns (m,num_labels) matrix where each column corresoponds to an example\n",
    "    all indexes are 0, each column contains a single 1, the row corresponding to the answer'''\n",
    "    m = np.size(y)\n",
    "    out = np.zeros((m, num_labels))\n",
    "    for row in range(0, m):\n",
    "        label = int(y[row])\n",
    "        out[row, label] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward(X,y):\n",
    "    y_k = return_labeled(y, num_labels) # output matrix used for cost evaluation\n",
    "    m = len(y)\n",
    "    # Forward propogation\n",
    "    a1 = np.c_[np.ones((m,1)), X]   # layer 1 : adding a bias column of 1's to X. (m, input_size + 1)\n",
    "    z2 = a1.dot(theta1.T)           # layer 2 matrix calculation\n",
    "    a2 = sigmoid(z2)                # activation of layer 2: shape(m, hidden_layer_size)\n",
    "    a2 = np.c_[np.ones((m, 1)), a2] # adding a bias column of 1's : shape(m, hidden_layer_size + 1)\n",
    "    z3 = a2.dot(theta2.T)           # layer3 || output layer calculation\n",
    "    a3 = sigmoid(z3)                # activation of output layer: size = (m, num_labels)\n",
    "    \n",
    "    # Cost function\n",
    "    inner_term0 = (-y_k * np.log(a3))\n",
    "    inner_term1 = (1 - y_k) * np.log(1 - a3)\n",
    "    left_side = np.sum(inner_term0 - inner_term1) / m\n",
    "    right_side = np.sum(theta1[:, 1:] ** 2) + np.sum(theta2[:,1:] ** 2) # sum of all theta vals squred excluding theta index0 \n",
    "    right_side = (lam / 2 / m) * right_side\n",
    "    cost = left_side + right_side\n",
    "    \n",
    "    # Back propogation\n",
    "#     print(f'shape of a3: {np.shape(a3)}')\n",
    "#     print(f'shape of y_k: {np.shape(y_k)}')\n",
    "    print(a3)\n",
    "    delta3 = a3 - y_k\n",
    "    delta2 = delta3.dot(theta2)[:,1:] * dx_sigmoid(z2) # excluding bias\n",
    "    Gradient1 = (delta2.T).dot(a1)\n",
    "    Gradient2 = (delta3.T).dot(a2)\n",
    "    \n",
    "#     print(f'Gradient 1: {Gradient1}')\n",
    "#     print(f'Gradient 2: {Gradient2}')\n",
    "\n",
    "    \n",
    "    return cost, a3, Gradient1, Gradient2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_same(ar):\n",
    "    for i in range(0, len(ar) - 1):\n",
    "        if(ar[i] != ar[i + 1]):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50950356 0.51501518 0.47593525 ... 0.50454888 0.49093125 0.50636233]\n",
      " [0.5094905  0.51504636 0.47589373 ... 0.50453575 0.4910308  0.50643268]\n",
      " [0.5095413  0.51498973 0.47595636 ... 0.50454132 0.49098482 0.5064939 ]\n",
      " ...\n",
      " [0.50959752 0.51498351 0.47584723 ... 0.50448207 0.49098047 0.50651573]\n",
      " [0.50953366 0.51517582 0.47600034 ... 0.50450733 0.49107216 0.50646702]\n",
      " [0.50955807 0.51490358 0.47590745 ... 0.50452401 0.49089121 0.50650077]]\n",
      "rats\n",
      "[11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\n",
      "(40,)\n",
      "(26,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 40\n",
    "lam = 2.5 # Lambda used for regularization in cost function\n",
    "\n",
    "\n",
    "# reinitialize thetas\n",
    "theta1 = rand_initialize_weights(input_layer_size, hidden_layer_size)\n",
    "theta2 = rand_initialize_weights(hidden_layer_size, num_labels)\n",
    "\n",
    "losses, accuracies = [], []\n",
    "samp = np.random.randint(0, X.shape[0], size=(batch_size))\n",
    "X_train = X[samp]\n",
    "y_train = y[samp]\n",
    "J, h_x, grad1, grad2 = forward_backward(X_train, y_train)\n",
    "\n",
    "\n",
    "prediction = np.argmax(h_x, axis=1)\n",
    "\n",
    "if(check_same(prediction)):\n",
    "    print('rats')\n",
    "else:\n",
    "    print('im so happy')\n",
    "\n",
    "print(prediction)\n",
    "xi = np.argmax(h_x, axis=0)\n",
    "print(np.shape(prediction))\n",
    "print(np.shape(xi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model training\n",
    "\n",
    "# for i in (t := trange(1000)):\n",
    "#     samp = np.random.randint(0, X.shape[0], size=(batch_size))\n",
    "#     X_train = X[samp]\n",
    "#     y_train = y[samp]\n",
    "#     J, h_x, grad1, grad2 = forward_backward(X_train, y_train)\n",
    "    \n",
    "#     prediction = np.argmax(h_x, axis=1)\n",
    "# #     if(check_same(prediction)):\n",
    "# #         print(\"all the same\")\n",
    "#     accuracy = (prediction == y).mean()\n",
    "    \n",
    "#     # Gradient descent:\n",
    "#     theta1 = theta1 - (learning_rate * grad1)\n",
    "#     theta2 = theta2 - (learning_rate * grad2)\n",
    "    \n",
    "#     loss = J.mean()\n",
    "#     losses.append(loss)\n",
    "    \n",
    "#     accuracies.append(accuracy)\n",
    "#     t.set_description(\"loss %.2f accuracy %.2f\" % (loss, accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
